{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "38769b1f53c72ff86450cf729f4dd42eb6dc200bf64e42232d27ac83b9528a7d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Assignment 14 : Batch RL\n",
    "\n",
    "## 1) LSTD algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "from rl.markov_process import TransitionStep\n",
    "\n",
    "A = TypeVar('A')\n",
    "S = TypeVar('S')\n",
    "X = TypeVar('X')\n",
    "\n",
    "def LSTD(feature_functions : Sequence[Callable[[X], float]],\n",
    "        trace : Iterable[TransitionStep[S]],\n",
    "        gamma : float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "            LEAST SQUARES TEMPORAL DIFFERENCE\n",
    "        params:\n",
    "            -feature_functions : functions mapping the state to different features\n",
    "            -trace : simulation trace (sequence of steps)\n",
    "            -gamma : discount factor\n",
    "        returns:\n",
    "            weight vector associated with the linear regression mapping feature functions values to predicted V.\n",
    "    \"\"\"\n",
    "    m = len(feature_functions)\n",
    "    A = np.zeros((m,m))\n",
    "    b = np.zeros((m,1))\n",
    "    for i,step in enumerate(trace):\n",
    "        phi = np.array([f(step.state) for f in feature_functions ]).reshape(-1,1)\n",
    "        phi_next = np.array([f(step.next_state) for f in feature_functions ]).reshape(-1,1)\n",
    "        A += np.outer(phi, phi - gamma * phi_next)\n",
    "        b += phi * step.reward\n",
    "    return np.linalg.inv(A).dot(b).flatten()\n",
    "\n"
   ]
  },
  {
   "source": [
    "## 2) LSPI : Least Squares Policy Iteration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.markov_decision_process import TransitionStep\n",
    "Batch = Iterable[TransitionStep[S,A]] # a changer pour inclure action ?\n",
    "\n",
    "def LSPI(feature_functions : Sequence[Callable[[X], float]],\n",
    "        batches : Iterable[Batch],\n",
    "        gamma : float,\n",
    "        action_space,\n",
    "        cold_start : Optional[np.ndarray] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "            LEAST SQUARES POLICY ITERATION\n",
    "        params:\n",
    "            -feature_functions : functions mapping the state to different features\n",
    "            -batches : batches of experiences\n",
    "            -gamma : discount factor\n",
    "            -cold_start : initial weights\n",
    "        returns:\n",
    "            weights for the linear mapping from (s,a) pairs to approximate Q-values using feature_functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def linear_Q_approx(W:np.ndarray) -> Callable[[X], float]:\n",
    "        return lambda s_a : sum([w*f(s_a) for w,f in zip(W,feature_functions)])\n",
    "\n",
    "    def pi_D(Q_function : Callable[[X], float]) -> Callable[[S], float]:\n",
    "        return lambda s : action_space[np.argmax([Q_function(s,a) for a in action_space])]\n",
    "\n",
    "    m = len(feature_functions)\n",
    "\n",
    "    W = np.random.randn(m,) if cold_start is None else cold_start #initial weights\n",
    "    \n",
    "    for batch in batches:\n",
    "        A = np.zeros((m,m))\n",
    "        b = np.zeros((m,1))\n",
    "        Q_function = linear_Q_approx(W)\n",
    "        pi = pi_D(Q_function)\n",
    "        for i,step in enumerate(trace):\n",
    "            phi = np.array([f((step.state, step.action)) for f in feature_functions ]).reshape(-1,1)\n",
    "            phi_next = np.array([f( (step.next_state, pi(step.next_state)) ) for f in feature_functions]).reshape(-1,1)\n",
    "\n",
    "            A += np.outer(phi, phi - gamma * phi_next)\n",
    "            b += phi * step.reward\n",
    "\n",
    "        W = np.linalg.inv(A).dot(b).flatten()\n",
    "\n",
    "    return W"
   ]
  },
  {
   "source": [
    "## 3) LSPI for American Options Pricing "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Price = float\n",
    "Continue = True\n",
    "Exercise = False\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class AmericanState:\n",
    "    '''American option state as defined in the course\n",
    "    '''\n",
    "    time: int\n",
    "    price_history : Sequence[Price]\n",
    "\n",
    "    def current_price(self) -> Price:\n",
    "        return self.price_history[-1]\n",
    "\n",
    "\n",
    "def american_LSPI(feature_functions : Sequence[Callable[[AmericanState], float]],\n",
    "        PriceTrajectories : Iterable[Sequence[Price]],\n",
    "        gamma : float,\n",
    "        K : float,\n",
    "        T :int,\n",
    "        cold_start : Optional[np.ndarray] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "            LEAST SQUARES POLICY ITERATION\n",
    "        params:\n",
    "            -feature_functions : functions mapping the state to different features\n",
    "            -PriceTrajectories : Sequence of Price lists of the security of length T\n",
    "            -gamma : discount factor\n",
    "            -K : strike price of the option\n",
    "            -T : maturity date of ther option\n",
    "            -cold_start : initial weights\n",
    "        returns:\n",
    "            weights for the linear mapping from states_action pairs to approximate Q-values for 'continue' action using feature_functions.\n",
    "    \"\"\"\n",
    "\n",
    "    def linear_Q_approx(W:np.ndarray) -> Callable[[X], float]:\n",
    "        return lambda s_a : sum([w*f(s_a[0]) for w,f in zip(W,feature_functions)]) if s_a[1] else g(s)\n",
    "\n",
    "    def g(s):\n",
    "        return max(s.current_price()-K,0)\n",
    "        \n",
    "    def pi_D(Q_function : Callable[[X], float]) -> Callable[[S], float]:\n",
    "        return lambda s : Continue if Q_function(s) > g(s) and s.time < T else Exercise\n",
    "\n",
    "    m = len(feature_functions)\n",
    "\n",
    "    W = np.random.randn(m,) if cold_start is None else cold_start #initial weights\n",
    "    \n",
    "    for price_traj in PriceTrajectories:\n",
    "        if len(price_traj) != T+1:\n",
    "            continue\n",
    "        state = AmericanState(0,[])\n",
    "        next_state = AmericanState(1,[price_traj[0]])\n",
    "\n",
    "        A = np.zeros((m,m))\n",
    "        b = np.zeros((m,1))\n",
    "        Q_function = linear_Q_approx(W)\n",
    "        pi = pi_D(Q_function)\n",
    "        for i,price in enumerate(price_traj[:T]):\n",
    "            state = next_state\n",
    "            next_state = AmericanState(next_state.time + 1,next_state.price_history + [price])\n",
    "\n",
    "            phi = np.array([f(state, Continue) for f in feature_functions]).reshape(-1,1)\n",
    "            phi_next = np.array([f( (next_state, pi(next_state)) ) for f in feature_functions]).reshape(-1,1)\n",
    "\n",
    "            A += np.outer(phi, phi - (Q_function((next_state,Continue)) >= g(next_state)) *gamma * phi_next)\n",
    "            b += gamma * (Q_function((next_state,Continue)) < g(next_state))  * g(next_state) * phi\n",
    "\n",
    "        W = np.linalg.inv(A).dot(b).flatten()\n",
    "\n",
    "    return W\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 20\n",
    "K = 2\n",
    "\n",
    "W = american_LSPI(feature_functions = [lambda s : s.current_price(), lambda s: 1],\n",
    "        PriceTrajectories  = np.random.randn(10,T) * 2* np.random.rand(10).reshape(-1,1),\n",
    "        gamma = 0.95,\n",
    "        K = K ,\n",
    "        T  = T,\n",
    "        cold_start  = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.14971897  0.01542418] +/-  [0.97354472 1.04338781]\n"
     ]
    }
   ],
   "source": [
    "T = 100\n",
    "K = 3\n",
    "Ws = np.array([american_LSPI(feature_functions = [lambda s : s.current_price()/K, lambda s: 1],\n",
    "        PriceTrajectories  = np.random.randn(1000,T) * 2* np.random.rand(1000).reshape(-1,1),\n",
    "        gamma = 0.95,\n",
    "        K = K ,\n",
    "        T  = T,\n",
    "        cold_start  = None) for k in range(100)])\n",
    "\n",
    "print(f'{Ws.mean(0)} +/-  {Ws.std(0)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}